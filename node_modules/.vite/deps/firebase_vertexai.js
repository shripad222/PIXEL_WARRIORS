import {
  __asyncGenerator,
  __await
} from "./chunk-YMRPPILD.js";
import {
  Component,
  FirebaseError,
  Logger,
  _getProvider,
  _isFirebaseServerApp,
  _registerComponent,
  getApp,
  getModularInstance,
  registerVersion
} from "./chunk-LFFDCABK.js";
import "./chunk-5WRI5ZAA.js";

// node_modules/@firebase/ai/dist/esm/index.esm2017.js
var name = "@firebase/ai";
var version = "1.4.1";
var AI_TYPE = "AI";
var DEFAULT_LOCATION = "us-central1";
var DEFAULT_BASE_URL = "https://firebasevertexai.googleapis.com";
var DEFAULT_API_VERSION = "v1beta";
var PACKAGE_VERSION = version;
var LANGUAGE_TAG = "gl-js";
var DEFAULT_FETCH_TIMEOUT_MS = 180 * 1e3;
var POSSIBLE_ROLES = ["user", "model", "function", "system"];
var HarmCategory;
(function(HarmCategory2) {
  HarmCategory2["HARM_CATEGORY_HATE_SPEECH"] = "HARM_CATEGORY_HATE_SPEECH";
  HarmCategory2["HARM_CATEGORY_SEXUALLY_EXPLICIT"] = "HARM_CATEGORY_SEXUALLY_EXPLICIT";
  HarmCategory2["HARM_CATEGORY_HARASSMENT"] = "HARM_CATEGORY_HARASSMENT";
  HarmCategory2["HARM_CATEGORY_DANGEROUS_CONTENT"] = "HARM_CATEGORY_DANGEROUS_CONTENT";
})(HarmCategory || (HarmCategory = {}));
var HarmBlockThreshold;
(function(HarmBlockThreshold2) {
  HarmBlockThreshold2["BLOCK_LOW_AND_ABOVE"] = "BLOCK_LOW_AND_ABOVE";
  HarmBlockThreshold2["BLOCK_MEDIUM_AND_ABOVE"] = "BLOCK_MEDIUM_AND_ABOVE";
  HarmBlockThreshold2["BLOCK_ONLY_HIGH"] = "BLOCK_ONLY_HIGH";
  HarmBlockThreshold2["BLOCK_NONE"] = "BLOCK_NONE";
  HarmBlockThreshold2["OFF"] = "OFF";
})(HarmBlockThreshold || (HarmBlockThreshold = {}));
var HarmBlockMethod;
(function(HarmBlockMethod2) {
  HarmBlockMethod2["SEVERITY"] = "SEVERITY";
  HarmBlockMethod2["PROBABILITY"] = "PROBABILITY";
})(HarmBlockMethod || (HarmBlockMethod = {}));
var HarmProbability;
(function(HarmProbability2) {
  HarmProbability2["NEGLIGIBLE"] = "NEGLIGIBLE";
  HarmProbability2["LOW"] = "LOW";
  HarmProbability2["MEDIUM"] = "MEDIUM";
  HarmProbability2["HIGH"] = "HIGH";
})(HarmProbability || (HarmProbability = {}));
var HarmSeverity;
(function(HarmSeverity2) {
  HarmSeverity2["HARM_SEVERITY_NEGLIGIBLE"] = "HARM_SEVERITY_NEGLIGIBLE";
  HarmSeverity2["HARM_SEVERITY_LOW"] = "HARM_SEVERITY_LOW";
  HarmSeverity2["HARM_SEVERITY_MEDIUM"] = "HARM_SEVERITY_MEDIUM";
  HarmSeverity2["HARM_SEVERITY_HIGH"] = "HARM_SEVERITY_HIGH";
  HarmSeverity2["HARM_SEVERITY_UNSUPPORTED"] = "HARM_SEVERITY_UNSUPPORTED";
})(HarmSeverity || (HarmSeverity = {}));
var BlockReason;
(function(BlockReason2) {
  BlockReason2["SAFETY"] = "SAFETY";
  BlockReason2["OTHER"] = "OTHER";
  BlockReason2["BLOCKLIST"] = "BLOCKLIST";
  BlockReason2["PROHIBITED_CONTENT"] = "PROHIBITED_CONTENT";
})(BlockReason || (BlockReason = {}));
var FinishReason;
(function(FinishReason2) {
  FinishReason2["STOP"] = "STOP";
  FinishReason2["MAX_TOKENS"] = "MAX_TOKENS";
  FinishReason2["SAFETY"] = "SAFETY";
  FinishReason2["RECITATION"] = "RECITATION";
  FinishReason2["OTHER"] = "OTHER";
  FinishReason2["BLOCKLIST"] = "BLOCKLIST";
  FinishReason2["PROHIBITED_CONTENT"] = "PROHIBITED_CONTENT";
  FinishReason2["SPII"] = "SPII";
  FinishReason2["MALFORMED_FUNCTION_CALL"] = "MALFORMED_FUNCTION_CALL";
})(FinishReason || (FinishReason = {}));
var FunctionCallingMode;
(function(FunctionCallingMode2) {
  FunctionCallingMode2["AUTO"] = "AUTO";
  FunctionCallingMode2["ANY"] = "ANY";
  FunctionCallingMode2["NONE"] = "NONE";
})(FunctionCallingMode || (FunctionCallingMode = {}));
var Modality;
(function(Modality2) {
  Modality2["MODALITY_UNSPECIFIED"] = "MODALITY_UNSPECIFIED";
  Modality2["TEXT"] = "TEXT";
  Modality2["IMAGE"] = "IMAGE";
  Modality2["VIDEO"] = "VIDEO";
  Modality2["AUDIO"] = "AUDIO";
  Modality2["DOCUMENT"] = "DOCUMENT";
})(Modality || (Modality = {}));
var ResponseModality = {
  /**
   * Text.
   * @beta
   */
  TEXT: "TEXT",
  /**
   * Image.
   * @beta
   */
  IMAGE: "IMAGE"
};
var SchemaType;
(function(SchemaType2) {
  SchemaType2["STRING"] = "string";
  SchemaType2["NUMBER"] = "number";
  SchemaType2["INTEGER"] = "integer";
  SchemaType2["BOOLEAN"] = "boolean";
  SchemaType2["ARRAY"] = "array";
  SchemaType2["OBJECT"] = "object";
})(SchemaType || (SchemaType = {}));
var ImagenSafetyFilterLevel;
(function(ImagenSafetyFilterLevel2) {
  ImagenSafetyFilterLevel2["BLOCK_LOW_AND_ABOVE"] = "block_low_and_above";
  ImagenSafetyFilterLevel2["BLOCK_MEDIUM_AND_ABOVE"] = "block_medium_and_above";
  ImagenSafetyFilterLevel2["BLOCK_ONLY_HIGH"] = "block_only_high";
  ImagenSafetyFilterLevel2["BLOCK_NONE"] = "block_none";
})(ImagenSafetyFilterLevel || (ImagenSafetyFilterLevel = {}));
var ImagenPersonFilterLevel;
(function(ImagenPersonFilterLevel2) {
  ImagenPersonFilterLevel2["BLOCK_ALL"] = "dont_allow";
  ImagenPersonFilterLevel2["ALLOW_ADULT"] = "allow_adult";
  ImagenPersonFilterLevel2["ALLOW_ALL"] = "allow_all";
})(ImagenPersonFilterLevel || (ImagenPersonFilterLevel = {}));
var ImagenAspectRatio;
(function(ImagenAspectRatio2) {
  ImagenAspectRatio2["SQUARE"] = "1:1";
  ImagenAspectRatio2["LANDSCAPE_3x4"] = "3:4";
  ImagenAspectRatio2["PORTRAIT_4x3"] = "4:3";
  ImagenAspectRatio2["LANDSCAPE_16x9"] = "16:9";
  ImagenAspectRatio2["PORTRAIT_9x16"] = "9:16";
})(ImagenAspectRatio || (ImagenAspectRatio = {}));
var BackendType = {
  /**
   * Identifies the backend service for the Vertex AI Gemini API provided through Google Cloud.
   * Use this constant when creating a {@link VertexAIBackend} configuration.
   */
  VERTEX_AI: "VERTEX_AI",
  /**
   * Identifies the backend service for the Gemini Developer API ({@link https://ai.google/ | Google AI}).
   * Use this constant when creating a {@link GoogleAIBackend} configuration.
   */
  GOOGLE_AI: "GOOGLE_AI"
};
var Backend = class {
  /**
   * Protected constructor for use by subclasses.
   * @param type - The backend type.
   */
  constructor(type) {
    this.backendType = type;
  }
};
var GoogleAIBackend = class extends Backend {
  /**
   * Creates a configuration object for the Gemini Developer API backend.
   */
  constructor() {
    super(BackendType.GOOGLE_AI);
  }
};
var VertexAIBackend = class extends Backend {
  /**
   * Creates a configuration object for the Vertex AI backend.
   *
   * @param location - The region identifier, defaulting to `us-central1`;
   * see {@link https://firebase.google.com/docs/vertex-ai/locations#available-locations | Vertex AI locations}
   * for a list of supported locations.
   */
  constructor(location = DEFAULT_LOCATION) {
    super(BackendType.VERTEX_AI);
    if (!location) {
      this.location = DEFAULT_LOCATION;
    } else {
      this.location = location;
    }
  }
};
var AIService = class {
  constructor(app, backend, authProvider, appCheckProvider) {
    this.app = app;
    this.backend = backend;
    const appCheck = appCheckProvider === null || appCheckProvider === void 0 ? void 0 : appCheckProvider.getImmediate({ optional: true });
    const auth = authProvider === null || authProvider === void 0 ? void 0 : authProvider.getImmediate({ optional: true });
    this.auth = auth || null;
    this.appCheck = appCheck || null;
    if (backend instanceof VertexAIBackend) {
      this.location = backend.location;
    } else {
      this.location = "";
    }
  }
  _delete() {
    return Promise.resolve();
  }
};
var AIError = class _AIError extends FirebaseError {
  /**
   * Constructs a new instance of the `AIError` class.
   *
   * @param code - The error code from {@link AIErrorCode}.
   * @param message - A human-readable message describing the error.
   * @param customErrorData - Optional error data.
   */
  constructor(code, message, customErrorData) {
    const service = AI_TYPE;
    const fullCode = `${service}/${code}`;
    const fullMessage = `${service}: ${message} (${fullCode})`;
    super(code, fullMessage);
    this.code = code;
    this.customErrorData = customErrorData;
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, _AIError);
    }
    Object.setPrototypeOf(this, _AIError.prototype);
    this.toString = () => fullMessage;
  }
};
function encodeInstanceIdentifier(backend) {
  if (backend instanceof GoogleAIBackend) {
    return `${AI_TYPE}/googleai`;
  } else if (backend instanceof VertexAIBackend) {
    return `${AI_TYPE}/vertexai/${backend.location}`;
  } else {
    throw new AIError("error", `Invalid backend: ${JSON.stringify(backend.backendType)}`);
  }
}
function decodeInstanceIdentifier(instanceIdentifier) {
  const identifierParts = instanceIdentifier.split("/");
  if (identifierParts[0] !== AI_TYPE) {
    throw new AIError("error", `Invalid instance identifier, unknown prefix '${identifierParts[0]}'`);
  }
  const backendType = identifierParts[1];
  switch (backendType) {
    case "vertexai":
      const location = identifierParts[2];
      if (!location) {
        throw new AIError("error", `Invalid instance identifier, unknown location '${instanceIdentifier}'`);
      }
      return new VertexAIBackend(location);
    case "googleai":
      return new GoogleAIBackend();
    default:
      throw new AIError("error", `Invalid instance identifier string: '${instanceIdentifier}'`);
  }
}
var AIModel = class _AIModel {
  /**
   * Constructs a new instance of the {@link AIModel} class.
   *
   * This constructor should only be called from subclasses that provide
   * a model API.
   *
   * @param ai - an {@link AI} instance.
   * @param modelName - The name of the model being used. It can be in one of the following formats:
   * - `my-model` (short name, will resolve to `publishers/google/models/my-model`)
   * - `models/my-model` (will resolve to `publishers/google/models/my-model`)
   * - `publishers/my-publisher/models/my-model` (fully qualified model name)
   *
   * @throws If the `apiKey` or `projectId` fields are missing in your
   * Firebase config.
   *
   * @internal
   */
  constructor(ai, modelName) {
    var _a, _b, _c, _d, _e, _f;
    if (!((_b = (_a = ai.app) === null || _a === void 0 ? void 0 : _a.options) === null || _b === void 0 ? void 0 : _b.apiKey)) {
      throw new AIError("no-api-key", `The "apiKey" field is empty in the local Firebase config. Firebase AI requires this field to contain a valid API key.`);
    } else if (!((_d = (_c = ai.app) === null || _c === void 0 ? void 0 : _c.options) === null || _d === void 0 ? void 0 : _d.projectId)) {
      throw new AIError("no-project-id", `The "projectId" field is empty in the local Firebase config. Firebase AI requires this field to contain a valid project ID.`);
    } else if (!((_f = (_e = ai.app) === null || _e === void 0 ? void 0 : _e.options) === null || _f === void 0 ? void 0 : _f.appId)) {
      throw new AIError("no-app-id", `The "appId" field is empty in the local Firebase config. Firebase AI requires this field to contain a valid app ID.`);
    } else {
      this._apiSettings = {
        apiKey: ai.app.options.apiKey,
        project: ai.app.options.projectId,
        appId: ai.app.options.appId,
        automaticDataCollectionEnabled: ai.app.automaticDataCollectionEnabled,
        location: ai.location,
        backend: ai.backend
      };
      if (_isFirebaseServerApp(ai.app) && ai.app.settings.appCheckToken) {
        const token = ai.app.settings.appCheckToken;
        this._apiSettings.getAppCheckToken = () => {
          return Promise.resolve({ token });
        };
      } else if (ai.appCheck) {
        this._apiSettings.getAppCheckToken = () => ai.appCheck.getToken();
      }
      if (ai.auth) {
        this._apiSettings.getAuthToken = () => ai.auth.getToken();
      }
      this.model = _AIModel.normalizeModelName(modelName, this._apiSettings.backend.backendType);
    }
  }
  /**
   * Normalizes the given model name to a fully qualified model resource name.
   *
   * @param modelName - The model name to normalize.
   * @returns The fully qualified model resource name.
   *
   * @internal
   */
  static normalizeModelName(modelName, backendType) {
    if (backendType === BackendType.GOOGLE_AI) {
      return _AIModel.normalizeGoogleAIModelName(modelName);
    } else {
      return _AIModel.normalizeVertexAIModelName(modelName);
    }
  }
  /**
   * @internal
   */
  static normalizeGoogleAIModelName(modelName) {
    return `models/${modelName}`;
  }
  /**
   * @internal
   */
  static normalizeVertexAIModelName(modelName) {
    let model;
    if (modelName.includes("/")) {
      if (modelName.startsWith("models/")) {
        model = `publishers/google/${modelName}`;
      } else {
        model = modelName;
      }
    } else {
      model = `publishers/google/models/${modelName}`;
    }
    return model;
  }
};
var logger = new Logger("@firebase/vertexai");
var Task;
(function(Task2) {
  Task2["GENERATE_CONTENT"] = "generateContent";
  Task2["STREAM_GENERATE_CONTENT"] = "streamGenerateContent";
  Task2["COUNT_TOKENS"] = "countTokens";
  Task2["PREDICT"] = "predict";
})(Task || (Task = {}));
var RequestUrl = class {
  constructor(model, task, apiSettings, stream, requestOptions) {
    this.model = model;
    this.task = task;
    this.apiSettings = apiSettings;
    this.stream = stream;
    this.requestOptions = requestOptions;
  }
  toString() {
    const url = new URL(this.baseUrl);
    url.pathname = `/${this.apiVersion}/${this.modelPath}:${this.task}`;
    url.search = this.queryParams.toString();
    return url.toString();
  }
  get baseUrl() {
    var _a;
    return ((_a = this.requestOptions) === null || _a === void 0 ? void 0 : _a.baseUrl) || DEFAULT_BASE_URL;
  }
  get apiVersion() {
    return DEFAULT_API_VERSION;
  }
  get modelPath() {
    if (this.apiSettings.backend instanceof GoogleAIBackend) {
      return `projects/${this.apiSettings.project}/${this.model}`;
    } else if (this.apiSettings.backend instanceof VertexAIBackend) {
      return `projects/${this.apiSettings.project}/locations/${this.apiSettings.backend.location}/${this.model}`;
    } else {
      throw new AIError("error", `Invalid backend: ${JSON.stringify(this.apiSettings.backend)}`);
    }
  }
  get queryParams() {
    const params = new URLSearchParams();
    if (this.stream) {
      params.set("alt", "sse");
    }
    return params;
  }
};
function getClientHeaders() {
  const loggingTags = [];
  loggingTags.push(`${LANGUAGE_TAG}/${PACKAGE_VERSION}`);
  loggingTags.push(`fire/${PACKAGE_VERSION}`);
  return loggingTags.join(" ");
}
async function getHeaders(url) {
  const headers = new Headers();
  headers.append("Content-Type", "application/json");
  headers.append("x-goog-api-client", getClientHeaders());
  headers.append("x-goog-api-key", url.apiSettings.apiKey);
  if (url.apiSettings.automaticDataCollectionEnabled) {
    headers.append("X-Firebase-Appid", url.apiSettings.appId);
  }
  if (url.apiSettings.getAppCheckToken) {
    const appCheckToken = await url.apiSettings.getAppCheckToken();
    if (appCheckToken) {
      headers.append("X-Firebase-AppCheck", appCheckToken.token);
      if (appCheckToken.error) {
        logger.warn(`Unable to obtain a valid App Check token: ${appCheckToken.error.message}`);
      }
    }
  }
  if (url.apiSettings.getAuthToken) {
    const authToken = await url.apiSettings.getAuthToken();
    if (authToken) {
      headers.append("Authorization", `Firebase ${authToken.accessToken}`);
    }
  }
  return headers;
}
async function constructRequest(model, task, apiSettings, stream, body, requestOptions) {
  const url = new RequestUrl(model, task, apiSettings, stream, requestOptions);
  return {
    url: url.toString(),
    fetchOptions: {
      method: "POST",
      headers: await getHeaders(url),
      body
    }
  };
}
async function makeRequest(model, task, apiSettings, stream, body, requestOptions) {
  const url = new RequestUrl(model, task, apiSettings, stream, requestOptions);
  let response;
  let fetchTimeoutId;
  try {
    const request = await constructRequest(model, task, apiSettings, stream, body, requestOptions);
    const timeoutMillis = (requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.timeout) != null && requestOptions.timeout >= 0 ? requestOptions.timeout : DEFAULT_FETCH_TIMEOUT_MS;
    const abortController = new AbortController();
    fetchTimeoutId = setTimeout(() => abortController.abort(), timeoutMillis);
    request.fetchOptions.signal = abortController.signal;
    response = await fetch(request.url, request.fetchOptions);
    if (!response.ok) {
      let message = "";
      let errorDetails;
      try {
        const json = await response.json();
        message = json.error.message;
        if (json.error.details) {
          message += ` ${JSON.stringify(json.error.details)}`;
          errorDetails = json.error.details;
        }
      } catch (e) {
      }
      if (response.status === 403 && errorDetails.some((detail) => detail.reason === "SERVICE_DISABLED") && errorDetails.some((detail) => {
        var _a, _b;
        return (_b = (_a = detail.links) === null || _a === void 0 ? void 0 : _a[0]) === null || _b === void 0 ? void 0 : _b.description.includes("Google developers console API activation");
      })) {
        throw new AIError("api-not-enabled", `The Firebase AI SDK requires the Firebase AI API ('firebasevertexai.googleapis.com') to be enabled in your Firebase project. Enable this API by visiting the Firebase Console at https://console.firebase.google.com/project/${url.apiSettings.project}/genai/ and clicking "Get started". If you enabled this API recently, wait a few minutes for the action to propagate to our systems and then retry.`, {
          status: response.status,
          statusText: response.statusText,
          errorDetails
        });
      }
      throw new AIError("fetch-error", `Error fetching from ${url}: [${response.status} ${response.statusText}] ${message}`, {
        status: response.status,
        statusText: response.statusText,
        errorDetails
      });
    }
  } catch (e) {
    let err = e;
    if (e.code !== "fetch-error" && e.code !== "api-not-enabled" && e instanceof Error) {
      err = new AIError("error", `Error fetching from ${url.toString()}: ${e.message}`);
      err.stack = e.stack;
    }
    throw err;
  } finally {
    if (fetchTimeoutId) {
      clearTimeout(fetchTimeoutId);
    }
  }
  return response;
}
function createEnhancedContentResponse(response) {
  if (response.candidates && !response.candidates[0].hasOwnProperty("index")) {
    response.candidates[0].index = 0;
  }
  const responseWithHelpers = addHelpers(response);
  return responseWithHelpers;
}
function addHelpers(response) {
  response.text = () => {
    if (response.candidates && response.candidates.length > 0) {
      if (response.candidates.length > 1) {
        logger.warn(`This response had ${response.candidates.length} candidates. Returning text from the first candidate only. Access response.candidates directly to use the other candidates.`);
      }
      if (hadBadFinishReason(response.candidates[0])) {
        throw new AIError("response-error", `Response error: ${formatBlockErrorMessage(response)}. Response body stored in error.response`, {
          response
        });
      }
      return getText(response);
    } else if (response.promptFeedback) {
      throw new AIError("response-error", `Text not available. ${formatBlockErrorMessage(response)}`, {
        response
      });
    }
    return "";
  };
  response.inlineDataParts = () => {
    if (response.candidates && response.candidates.length > 0) {
      if (response.candidates.length > 1) {
        logger.warn(`This response had ${response.candidates.length} candidates. Returning data from the first candidate only. Access response.candidates directly to use the other candidates.`);
      }
      if (hadBadFinishReason(response.candidates[0])) {
        throw new AIError("response-error", `Response error: ${formatBlockErrorMessage(response)}. Response body stored in error.response`, {
          response
        });
      }
      return getInlineDataParts(response);
    } else if (response.promptFeedback) {
      throw new AIError("response-error", `Data not available. ${formatBlockErrorMessage(response)}`, {
        response
      });
    }
    return void 0;
  };
  response.functionCalls = () => {
    if (response.candidates && response.candidates.length > 0) {
      if (response.candidates.length > 1) {
        logger.warn(`This response had ${response.candidates.length} candidates. Returning function calls from the first candidate only. Access response.candidates directly to use the other candidates.`);
      }
      if (hadBadFinishReason(response.candidates[0])) {
        throw new AIError("response-error", `Response error: ${formatBlockErrorMessage(response)}. Response body stored in error.response`, {
          response
        });
      }
      return getFunctionCalls(response);
    } else if (response.promptFeedback) {
      throw new AIError("response-error", `Function call not available. ${formatBlockErrorMessage(response)}`, {
        response
      });
    }
    return void 0;
  };
  return response;
}
function getText(response) {
  var _a, _b, _c, _d;
  const textStrings = [];
  if ((_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0].content) === null || _b === void 0 ? void 0 : _b.parts) {
    for (const part of (_d = (_c = response.candidates) === null || _c === void 0 ? void 0 : _c[0].content) === null || _d === void 0 ? void 0 : _d.parts) {
      if (part.text) {
        textStrings.push(part.text);
      }
    }
  }
  if (textStrings.length > 0) {
    return textStrings.join("");
  } else {
    return "";
  }
}
function getFunctionCalls(response) {
  var _a, _b, _c, _d;
  const functionCalls = [];
  if ((_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0].content) === null || _b === void 0 ? void 0 : _b.parts) {
    for (const part of (_d = (_c = response.candidates) === null || _c === void 0 ? void 0 : _c[0].content) === null || _d === void 0 ? void 0 : _d.parts) {
      if (part.functionCall) {
        functionCalls.push(part.functionCall);
      }
    }
  }
  if (functionCalls.length > 0) {
    return functionCalls;
  } else {
    return void 0;
  }
}
function getInlineDataParts(response) {
  var _a, _b, _c, _d;
  const data = [];
  if ((_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0].content) === null || _b === void 0 ? void 0 : _b.parts) {
    for (const part of (_d = (_c = response.candidates) === null || _c === void 0 ? void 0 : _c[0].content) === null || _d === void 0 ? void 0 : _d.parts) {
      if (part.inlineData) {
        data.push(part);
      }
    }
  }
  if (data.length > 0) {
    return data;
  } else {
    return void 0;
  }
}
var badFinishReasons = [FinishReason.RECITATION, FinishReason.SAFETY];
function hadBadFinishReason(candidate) {
  return !!candidate.finishReason && badFinishReasons.includes(candidate.finishReason);
}
function formatBlockErrorMessage(response) {
  var _a, _b, _c;
  let message = "";
  if ((!response.candidates || response.candidates.length === 0) && response.promptFeedback) {
    message += "Response was blocked";
    if ((_a = response.promptFeedback) === null || _a === void 0 ? void 0 : _a.blockReason) {
      message += ` due to ${response.promptFeedback.blockReason}`;
    }
    if ((_b = response.promptFeedback) === null || _b === void 0 ? void 0 : _b.blockReasonMessage) {
      message += `: ${response.promptFeedback.blockReasonMessage}`;
    }
  } else if ((_c = response.candidates) === null || _c === void 0 ? void 0 : _c[0]) {
    const firstCandidate = response.candidates[0];
    if (hadBadFinishReason(firstCandidate)) {
      message += `Candidate was blocked due to ${firstCandidate.finishReason}`;
      if (firstCandidate.finishMessage) {
        message += `: ${firstCandidate.finishMessage}`;
      }
    }
  }
  return message;
}
async function handlePredictResponse(response) {
  var _a;
  const responseJson = await response.json();
  const images = [];
  let filteredReason = void 0;
  if (!responseJson.predictions || ((_a = responseJson.predictions) === null || _a === void 0 ? void 0 : _a.length) === 0) {
    throw new AIError("response-error", "No predictions or filtered reason received from Vertex AI. Please report this issue with the full error details at https://github.com/firebase/firebase-js-sdk/issues.");
  }
  for (const prediction of responseJson.predictions) {
    if (prediction.raiFilteredReason) {
      filteredReason = prediction.raiFilteredReason;
    } else if (prediction.mimeType && prediction.bytesBase64Encoded) {
      images.push({
        mimeType: prediction.mimeType,
        bytesBase64Encoded: prediction.bytesBase64Encoded
      });
    } else if (prediction.mimeType && prediction.gcsUri) {
      images.push({
        mimeType: prediction.mimeType,
        gcsURI: prediction.gcsUri
      });
    } else {
      throw new AIError("response-error", `Predictions array in response has missing properties. Response: ${JSON.stringify(responseJson)}`);
    }
  }
  return { images, filteredReason };
}
function mapGenerateContentRequest(generateContentRequest) {
  var _a, _b;
  (_a = generateContentRequest.safetySettings) === null || _a === void 0 ? void 0 : _a.forEach((safetySetting) => {
    if (safetySetting.method) {
      throw new AIError("unsupported", "SafetySetting.method is not supported in the the Gemini Developer API. Please remove this property.");
    }
  });
  if ((_b = generateContentRequest.generationConfig) === null || _b === void 0 ? void 0 : _b.topK) {
    const roundedTopK = Math.round(generateContentRequest.generationConfig.topK);
    if (roundedTopK !== generateContentRequest.generationConfig.topK) {
      logger.warn("topK in GenerationConfig has been rounded to the nearest integer to match the format for requests to the Gemini Developer API.");
      generateContentRequest.generationConfig.topK = roundedTopK;
    }
  }
  return generateContentRequest;
}
function mapGenerateContentResponse(googleAIResponse) {
  const generateContentResponse = {
    candidates: googleAIResponse.candidates ? mapGenerateContentCandidates(googleAIResponse.candidates) : void 0,
    prompt: googleAIResponse.promptFeedback ? mapPromptFeedback(googleAIResponse.promptFeedback) : void 0,
    usageMetadata: googleAIResponse.usageMetadata
  };
  return generateContentResponse;
}
function mapCountTokensRequest(countTokensRequest, model) {
  const mappedCountTokensRequest = {
    generateContentRequest: Object.assign({ model }, countTokensRequest)
  };
  return mappedCountTokensRequest;
}
function mapGenerateContentCandidates(candidates) {
  const mappedCandidates = [];
  let mappedSafetyRatings;
  if (mappedCandidates) {
    candidates.forEach((candidate) => {
      var _a;
      let citationMetadata;
      if (candidate.citationMetadata) {
        citationMetadata = {
          citations: candidate.citationMetadata.citationSources
        };
      }
      if (candidate.safetyRatings) {
        mappedSafetyRatings = candidate.safetyRatings.map((safetyRating) => {
          var _a2, _b, _c;
          return Object.assign(Object.assign({}, safetyRating), { severity: (_a2 = safetyRating.severity) !== null && _a2 !== void 0 ? _a2 : HarmSeverity.HARM_SEVERITY_UNSUPPORTED, probabilityScore: (_b = safetyRating.probabilityScore) !== null && _b !== void 0 ? _b : 0, severityScore: (_c = safetyRating.severityScore) !== null && _c !== void 0 ? _c : 0 });
        });
      }
      if ((_a = candidate.content) === null || _a === void 0 ? void 0 : _a.parts.some((part) => part === null || part === void 0 ? void 0 : part.videoMetadata)) {
        throw new AIError("unsupported", "Part.videoMetadata is not supported in the Gemini Developer API. Please remove this property.");
      }
      const mappedCandidate = {
        index: candidate.index,
        content: candidate.content,
        finishReason: candidate.finishReason,
        finishMessage: candidate.finishMessage,
        safetyRatings: mappedSafetyRatings,
        citationMetadata,
        groundingMetadata: candidate.groundingMetadata
      };
      mappedCandidates.push(mappedCandidate);
    });
  }
  return mappedCandidates;
}
function mapPromptFeedback(promptFeedback) {
  const mappedSafetyRatings = [];
  promptFeedback.safetyRatings.forEach((safetyRating) => {
    var _a, _b, _c;
    mappedSafetyRatings.push({
      category: safetyRating.category,
      probability: safetyRating.probability,
      severity: (_a = safetyRating.severity) !== null && _a !== void 0 ? _a : HarmSeverity.HARM_SEVERITY_UNSUPPORTED,
      probabilityScore: (_b = safetyRating.probabilityScore) !== null && _b !== void 0 ? _b : 0,
      severityScore: (_c = safetyRating.severityScore) !== null && _c !== void 0 ? _c : 0,
      blocked: safetyRating.blocked
    });
  });
  const mappedPromptFeedback = {
    blockReason: promptFeedback.blockReason,
    safetyRatings: mappedSafetyRatings,
    blockReasonMessage: promptFeedback.blockReasonMessage
  };
  return mappedPromptFeedback;
}
var responseLineRE = /^data\: (.*)(?:\n\n|\r\r|\r\n\r\n)/;
function processStream(response, apiSettings) {
  const inputStream = response.body.pipeThrough(new TextDecoderStream("utf8", { fatal: true }));
  const responseStream = getResponseStream(inputStream);
  const [stream1, stream2] = responseStream.tee();
  return {
    stream: generateResponseSequence(stream1, apiSettings),
    response: getResponsePromise(stream2, apiSettings)
  };
}
async function getResponsePromise(stream, apiSettings) {
  const allResponses = [];
  const reader = stream.getReader();
  while (true) {
    const { done, value } = await reader.read();
    if (done) {
      let generateContentResponse = aggregateResponses(allResponses);
      if (apiSettings.backend.backendType === BackendType.GOOGLE_AI) {
        generateContentResponse = mapGenerateContentResponse(generateContentResponse);
      }
      return createEnhancedContentResponse(generateContentResponse);
    }
    allResponses.push(value);
  }
}
function generateResponseSequence(stream, apiSettings) {
  return __asyncGenerator(this, arguments, function* generateResponseSequence_1() {
    const reader = stream.getReader();
    while (true) {
      const { value, done } = yield __await(reader.read());
      if (done) {
        break;
      }
      let enhancedResponse;
      if (apiSettings.backend.backendType === BackendType.GOOGLE_AI) {
        enhancedResponse = createEnhancedContentResponse(mapGenerateContentResponse(value));
      } else {
        enhancedResponse = createEnhancedContentResponse(value);
      }
      yield yield __await(enhancedResponse);
    }
  });
}
function getResponseStream(inputStream) {
  const reader = inputStream.getReader();
  const stream = new ReadableStream({
    start(controller) {
      let currentText = "";
      return pump();
      function pump() {
        return reader.read().then(({ value, done }) => {
          if (done) {
            if (currentText.trim()) {
              controller.error(new AIError("parse-failed", "Failed to parse stream"));
              return;
            }
            controller.close();
            return;
          }
          currentText += value;
          let match = currentText.match(responseLineRE);
          let parsedResponse;
          while (match) {
            try {
              parsedResponse = JSON.parse(match[1]);
            } catch (e) {
              controller.error(new AIError("parse-failed", `Error parsing JSON response: "${match[1]}`));
              return;
            }
            controller.enqueue(parsedResponse);
            currentText = currentText.substring(match[0].length);
            match = currentText.match(responseLineRE);
          }
          return pump();
        });
      }
    }
  });
  return stream;
}
function aggregateResponses(responses) {
  const lastResponse = responses[responses.length - 1];
  const aggregatedResponse = {
    promptFeedback: lastResponse === null || lastResponse === void 0 ? void 0 : lastResponse.promptFeedback
  };
  for (const response of responses) {
    if (response.candidates) {
      for (const candidate of response.candidates) {
        const i = candidate.index || 0;
        if (!aggregatedResponse.candidates) {
          aggregatedResponse.candidates = [];
        }
        if (!aggregatedResponse.candidates[i]) {
          aggregatedResponse.candidates[i] = {
            index: candidate.index
          };
        }
        aggregatedResponse.candidates[i].citationMetadata = candidate.citationMetadata;
        aggregatedResponse.candidates[i].finishReason = candidate.finishReason;
        aggregatedResponse.candidates[i].finishMessage = candidate.finishMessage;
        aggregatedResponse.candidates[i].safetyRatings = candidate.safetyRatings;
        if (candidate.content && candidate.content.parts) {
          if (!aggregatedResponse.candidates[i].content) {
            aggregatedResponse.candidates[i].content = {
              role: candidate.content.role || "user",
              parts: []
            };
          }
          const newPart = {};
          for (const part of candidate.content.parts) {
            if (part.text !== void 0) {
              if (part.text === "") {
                continue;
              }
              newPart.text = part.text;
            }
            if (part.functionCall) {
              newPart.functionCall = part.functionCall;
            }
            if (Object.keys(newPart).length === 0) {
              throw new AIError("invalid-content", "Part should have at least one property, but there are none. This is likely caused by a malformed response from the backend.");
            }
            aggregatedResponse.candidates[i].content.parts.push(newPart);
          }
        }
      }
    }
  }
  return aggregatedResponse;
}
async function generateContentStream(apiSettings, model, params, requestOptions) {
  if (apiSettings.backend.backendType === BackendType.GOOGLE_AI) {
    params = mapGenerateContentRequest(params);
  }
  const response = await makeRequest(
    model,
    Task.STREAM_GENERATE_CONTENT,
    apiSettings,
    /* stream */
    true,
    JSON.stringify(params),
    requestOptions
  );
  return processStream(response, apiSettings);
}
async function generateContent(apiSettings, model, params, requestOptions) {
  if (apiSettings.backend.backendType === BackendType.GOOGLE_AI) {
    params = mapGenerateContentRequest(params);
  }
  const response = await makeRequest(
    model,
    Task.GENERATE_CONTENT,
    apiSettings,
    /* stream */
    false,
    JSON.stringify(params),
    requestOptions
  );
  const generateContentResponse = await processGenerateContentResponse(response, apiSettings);
  const enhancedResponse = createEnhancedContentResponse(generateContentResponse);
  return {
    response: enhancedResponse
  };
}
async function processGenerateContentResponse(response, apiSettings) {
  const responseJson = await response.json();
  if (apiSettings.backend.backendType === BackendType.GOOGLE_AI) {
    return mapGenerateContentResponse(responseJson);
  } else {
    return responseJson;
  }
}
function formatSystemInstruction(input) {
  if (input == null) {
    return void 0;
  } else if (typeof input === "string") {
    return { role: "system", parts: [{ text: input }] };
  } else if (input.text) {
    return { role: "system", parts: [input] };
  } else if (input.parts) {
    if (!input.role) {
      return { role: "system", parts: input.parts };
    } else {
      return input;
    }
  }
}
function formatNewContent(request) {
  let newParts = [];
  if (typeof request === "string") {
    newParts = [{ text: request }];
  } else {
    for (const partOrString of request) {
      if (typeof partOrString === "string") {
        newParts.push({ text: partOrString });
      } else {
        newParts.push(partOrString);
      }
    }
  }
  return assignRoleToPartsAndValidateSendMessageRequest(newParts);
}
function assignRoleToPartsAndValidateSendMessageRequest(parts) {
  const userContent = { role: "user", parts: [] };
  const functionContent = { role: "function", parts: [] };
  let hasUserContent = false;
  let hasFunctionContent = false;
  for (const part of parts) {
    if ("functionResponse" in part) {
      functionContent.parts.push(part);
      hasFunctionContent = true;
    } else {
      userContent.parts.push(part);
      hasUserContent = true;
    }
  }
  if (hasUserContent && hasFunctionContent) {
    throw new AIError("invalid-content", "Within a single message, FunctionResponse cannot be mixed with other type of Part in the request for sending chat message.");
  }
  if (!hasUserContent && !hasFunctionContent) {
    throw new AIError("invalid-content", "No Content is provided for sending chat message.");
  }
  if (hasUserContent) {
    return userContent;
  }
  return functionContent;
}
function formatGenerateContentInput(params) {
  let formattedRequest;
  if (params.contents) {
    formattedRequest = params;
  } else {
    const content = formatNewContent(params);
    formattedRequest = { contents: [content] };
  }
  if (params.systemInstruction) {
    formattedRequest.systemInstruction = formatSystemInstruction(params.systemInstruction);
  }
  return formattedRequest;
}
function createPredictRequestBody(prompt, { gcsURI, imageFormat, addWatermark, numberOfImages = 1, negativePrompt, aspectRatio, safetyFilterLevel, personFilterLevel }) {
  const body = {
    instances: [
      {
        prompt
      }
    ],
    parameters: {
      storageUri: gcsURI,
      negativePrompt,
      sampleCount: numberOfImages,
      aspectRatio,
      outputOptions: imageFormat,
      addWatermark,
      safetyFilterLevel,
      personGeneration: personFilterLevel,
      includeRaiReason: true
    }
  };
  return body;
}
var VALID_PART_FIELDS = [
  "text",
  "inlineData",
  "functionCall",
  "functionResponse"
];
var VALID_PARTS_PER_ROLE = {
  user: ["text", "inlineData"],
  function: ["functionResponse"],
  model: ["text", "functionCall"],
  // System instructions shouldn't be in history anyway.
  system: ["text"]
};
var VALID_PREVIOUS_CONTENT_ROLES = {
  user: ["model"],
  function: ["model"],
  model: ["user", "function"],
  // System instructions shouldn't be in history.
  system: []
};
function validateChatHistory(history) {
  let prevContent = null;
  for (const currContent of history) {
    const { role, parts } = currContent;
    if (!prevContent && role !== "user") {
      throw new AIError("invalid-content", `First Content should be with role 'user', got ${role}`);
    }
    if (!POSSIBLE_ROLES.includes(role)) {
      throw new AIError("invalid-content", `Each item should include role field. Got ${role} but valid roles are: ${JSON.stringify(POSSIBLE_ROLES)}`);
    }
    if (!Array.isArray(parts)) {
      throw new AIError("invalid-content", `Content should have 'parts' but property with an array of Parts`);
    }
    if (parts.length === 0) {
      throw new AIError("invalid-content", `Each Content should have at least one part`);
    }
    const countFields = {
      text: 0,
      inlineData: 0,
      functionCall: 0,
      functionResponse: 0
    };
    for (const part of parts) {
      for (const key of VALID_PART_FIELDS) {
        if (key in part) {
          countFields[key] += 1;
        }
      }
    }
    const validParts = VALID_PARTS_PER_ROLE[role];
    for (const key of VALID_PART_FIELDS) {
      if (!validParts.includes(key) && countFields[key] > 0) {
        throw new AIError("invalid-content", `Content with role '${role}' can't contain '${key}' part`);
      }
    }
    if (prevContent) {
      const validPreviousContentRoles = VALID_PREVIOUS_CONTENT_ROLES[role];
      if (!validPreviousContentRoles.includes(prevContent.role)) {
        throw new AIError("invalid-content", `Content with role '${role}' can't follow '${prevContent.role}'. Valid previous roles: ${JSON.stringify(VALID_PREVIOUS_CONTENT_ROLES)}`);
      }
    }
    prevContent = currContent;
  }
}
var SILENT_ERROR = "SILENT_ERROR";
var ChatSession = class {
  constructor(apiSettings, model, params, requestOptions) {
    this.model = model;
    this.params = params;
    this.requestOptions = requestOptions;
    this._history = [];
    this._sendPromise = Promise.resolve();
    this._apiSettings = apiSettings;
    if (params === null || params === void 0 ? void 0 : params.history) {
      validateChatHistory(params.history);
      this._history = params.history;
    }
  }
  /**
   * Gets the chat history so far. Blocked prompts are not added to history.
   * Neither blocked candidates nor the prompts that generated them are added
   * to history.
   */
  async getHistory() {
    await this._sendPromise;
    return this._history;
  }
  /**
   * Sends a chat message and receives a non-streaming
   * {@link GenerateContentResult}
   */
  async sendMessage(request) {
    var _a, _b, _c, _d, _e;
    await this._sendPromise;
    const newContent = formatNewContent(request);
    const generateContentRequest = {
      safetySettings: (_a = this.params) === null || _a === void 0 ? void 0 : _a.safetySettings,
      generationConfig: (_b = this.params) === null || _b === void 0 ? void 0 : _b.generationConfig,
      tools: (_c = this.params) === null || _c === void 0 ? void 0 : _c.tools,
      toolConfig: (_d = this.params) === null || _d === void 0 ? void 0 : _d.toolConfig,
      systemInstruction: (_e = this.params) === null || _e === void 0 ? void 0 : _e.systemInstruction,
      contents: [...this._history, newContent]
    };
    let finalResult = {};
    this._sendPromise = this._sendPromise.then(() => generateContent(this._apiSettings, this.model, generateContentRequest, this.requestOptions)).then((result) => {
      var _a2, _b2;
      if (result.response.candidates && result.response.candidates.length > 0) {
        this._history.push(newContent);
        const responseContent = {
          parts: ((_a2 = result.response.candidates) === null || _a2 === void 0 ? void 0 : _a2[0].content.parts) || [],
          // Response seems to come back without a role set.
          role: ((_b2 = result.response.candidates) === null || _b2 === void 0 ? void 0 : _b2[0].content.role) || "model"
        };
        this._history.push(responseContent);
      } else {
        const blockErrorMessage = formatBlockErrorMessage(result.response);
        if (blockErrorMessage) {
          logger.warn(`sendMessage() was unsuccessful. ${blockErrorMessage}. Inspect response object for details.`);
        }
      }
      finalResult = result;
    });
    await this._sendPromise;
    return finalResult;
  }
  /**
   * Sends a chat message and receives the response as a
   * {@link GenerateContentStreamResult} containing an iterable stream
   * and a response promise.
   */
  async sendMessageStream(request) {
    var _a, _b, _c, _d, _e;
    await this._sendPromise;
    const newContent = formatNewContent(request);
    const generateContentRequest = {
      safetySettings: (_a = this.params) === null || _a === void 0 ? void 0 : _a.safetySettings,
      generationConfig: (_b = this.params) === null || _b === void 0 ? void 0 : _b.generationConfig,
      tools: (_c = this.params) === null || _c === void 0 ? void 0 : _c.tools,
      toolConfig: (_d = this.params) === null || _d === void 0 ? void 0 : _d.toolConfig,
      systemInstruction: (_e = this.params) === null || _e === void 0 ? void 0 : _e.systemInstruction,
      contents: [...this._history, newContent]
    };
    const streamPromise = generateContentStream(this._apiSettings, this.model, generateContentRequest, this.requestOptions);
    this._sendPromise = this._sendPromise.then(() => streamPromise).catch((_ignored) => {
      throw new Error(SILENT_ERROR);
    }).then((streamResult) => streamResult.response).then((response) => {
      if (response.candidates && response.candidates.length > 0) {
        this._history.push(newContent);
        const responseContent = Object.assign({}, response.candidates[0].content);
        if (!responseContent.role) {
          responseContent.role = "model";
        }
        this._history.push(responseContent);
      } else {
        const blockErrorMessage = formatBlockErrorMessage(response);
        if (blockErrorMessage) {
          logger.warn(`sendMessageStream() was unsuccessful. ${blockErrorMessage}. Inspect response object for details.`);
        }
      }
    }).catch((e) => {
      if (e.message !== SILENT_ERROR) {
        logger.error(e);
      }
    });
    return streamPromise;
  }
};
async function countTokens(apiSettings, model, params, requestOptions) {
  let body = "";
  if (apiSettings.backend.backendType === BackendType.GOOGLE_AI) {
    const mappedParams = mapCountTokensRequest(params, model);
    body = JSON.stringify(mappedParams);
  } else {
    body = JSON.stringify(params);
  }
  const response = await makeRequest(model, Task.COUNT_TOKENS, apiSettings, false, body, requestOptions);
  return response.json();
}
var GenerativeModel = class extends AIModel {
  constructor(ai, modelParams, requestOptions) {
    super(ai, modelParams.model);
    this.generationConfig = modelParams.generationConfig || {};
    this.safetySettings = modelParams.safetySettings || [];
    this.tools = modelParams.tools;
    this.toolConfig = modelParams.toolConfig;
    this.systemInstruction = formatSystemInstruction(modelParams.systemInstruction);
    this.requestOptions = requestOptions || {};
  }
  /**
   * Makes a single non-streaming call to the model
   * and returns an object containing a single {@link GenerateContentResponse}.
   */
  async generateContent(request) {
    const formattedParams = formatGenerateContentInput(request);
    return generateContent(this._apiSettings, this.model, Object.assign({ generationConfig: this.generationConfig, safetySettings: this.safetySettings, tools: this.tools, toolConfig: this.toolConfig, systemInstruction: this.systemInstruction }, formattedParams), this.requestOptions);
  }
  /**
   * Makes a single streaming call to the model
   * and returns an object containing an iterable stream that iterates
   * over all chunks in the streaming response as well as
   * a promise that returns the final aggregated response.
   */
  async generateContentStream(request) {
    const formattedParams = formatGenerateContentInput(request);
    return generateContentStream(this._apiSettings, this.model, Object.assign({ generationConfig: this.generationConfig, safetySettings: this.safetySettings, tools: this.tools, toolConfig: this.toolConfig, systemInstruction: this.systemInstruction }, formattedParams), this.requestOptions);
  }
  /**
   * Gets a new {@link ChatSession} instance which can be used for
   * multi-turn chats.
   */
  startChat(startChatParams) {
    return new ChatSession(this._apiSettings, this.model, Object.assign({ tools: this.tools, toolConfig: this.toolConfig, systemInstruction: this.systemInstruction, generationConfig: this.generationConfig, safetySettings: this.safetySettings }, startChatParams), this.requestOptions);
  }
  /**
   * Counts the tokens in the provided request.
   */
  async countTokens(request) {
    const formattedParams = formatGenerateContentInput(request);
    return countTokens(this._apiSettings, this.model, formattedParams);
  }
};
var ImagenModel = class extends AIModel {
  /**
   * Constructs a new instance of the {@link ImagenModel} class.
   *
   * @param ai - an {@link AI} instance.
   * @param modelParams - Parameters to use when making requests to Imagen.
   * @param requestOptions - Additional options to use when making requests.
   *
   * @throws If the `apiKey` or `projectId` fields are missing in your
   * Firebase config.
   */
  constructor(ai, modelParams, requestOptions) {
    const { model, generationConfig, safetySettings } = modelParams;
    super(ai, model);
    this.requestOptions = requestOptions;
    this.generationConfig = generationConfig;
    this.safetySettings = safetySettings;
  }
  /**
   * Generates images using the Imagen model and returns them as
   * base64-encoded strings.
   *
   * @param prompt - A text prompt describing the image(s) to generate.
   * @returns A promise that resolves to an {@link ImagenGenerationResponse}
   * object containing the generated images.
   *
   * @throws If the request to generate images fails. This happens if the
   * prompt is blocked.
   *
   * @remarks
   * If the prompt was not blocked, but one or more of the generated images were filtered, the
   * returned object will have a `filteredReason` property.
   * If all images are filtered, the `images` array will be empty.
   *
   * @beta
   */
  async generateImages(prompt) {
    const body = createPredictRequestBody(prompt, Object.assign(Object.assign({}, this.generationConfig), this.safetySettings));
    const response = await makeRequest(
      this.model,
      Task.PREDICT,
      this._apiSettings,
      /* stream */
      false,
      JSON.stringify(body),
      this.requestOptions
    );
    return handlePredictResponse(response);
  }
  /**
   * Generates images to Cloud Storage for Firebase using the Imagen model.
   *
   * @internal This method is temporarily internal.
   *
   * @param prompt - A text prompt describing the image(s) to generate.
   * @param gcsURI - The URI of file stored in a Cloud Storage for Firebase bucket.
   * This should be a directory. For example, `gs://my-bucket/my-directory/`.
   * @returns A promise that resolves to an {@link ImagenGenerationResponse}
   * object containing the URLs of the generated images.
   *
   * @throws If the request fails to generate images fails. This happens if
   * the prompt is blocked.
   *
   * @remarks
   * If the prompt was not blocked, but one or more of the generated images were filtered, the
   * returned object will have a `filteredReason` property.
   * If all images are filtered, the `images` array will be empty.
   */
  async generateImagesGCS(prompt, gcsURI) {
    const body = createPredictRequestBody(prompt, Object.assign(Object.assign({ gcsURI }, this.generationConfig), this.safetySettings));
    const response = await makeRequest(
      this.model,
      Task.PREDICT,
      this._apiSettings,
      /* stream */
      false,
      JSON.stringify(body),
      this.requestOptions
    );
    return handlePredictResponse(response);
  }
};
var Schema = class {
  constructor(schemaParams) {
    for (const paramKey in schemaParams) {
      this[paramKey] = schemaParams[paramKey];
    }
    this.type = schemaParams.type;
    this.nullable = schemaParams.hasOwnProperty("nullable") ? !!schemaParams.nullable : false;
  }
  /**
   * Defines how this Schema should be serialized as JSON.
   * See https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify#tojson_behavior
   * @internal
   */
  toJSON() {
    const obj = {
      type: this.type
    };
    for (const prop in this) {
      if (this.hasOwnProperty(prop) && this[prop] !== void 0) {
        if (prop !== "required" || this.type === SchemaType.OBJECT) {
          obj[prop] = this[prop];
        }
      }
    }
    return obj;
  }
  static array(arrayParams) {
    return new ArraySchema(arrayParams, arrayParams.items);
  }
  static object(objectParams) {
    return new ObjectSchema(objectParams, objectParams.properties, objectParams.optionalProperties);
  }
  // eslint-disable-next-line id-blacklist
  static string(stringParams) {
    return new StringSchema(stringParams);
  }
  static enumString(stringParams) {
    return new StringSchema(stringParams, stringParams.enum);
  }
  static integer(integerParams) {
    return new IntegerSchema(integerParams);
  }
  // eslint-disable-next-line id-blacklist
  static number(numberParams) {
    return new NumberSchema(numberParams);
  }
  // eslint-disable-next-line id-blacklist
  static boolean(booleanParams) {
    return new BooleanSchema(booleanParams);
  }
};
var IntegerSchema = class extends Schema {
  constructor(schemaParams) {
    super(Object.assign({ type: SchemaType.INTEGER }, schemaParams));
  }
};
var NumberSchema = class extends Schema {
  constructor(schemaParams) {
    super(Object.assign({ type: SchemaType.NUMBER }, schemaParams));
  }
};
var BooleanSchema = class extends Schema {
  constructor(schemaParams) {
    super(Object.assign({ type: SchemaType.BOOLEAN }, schemaParams));
  }
};
var StringSchema = class extends Schema {
  constructor(schemaParams, enumValues) {
    super(Object.assign({ type: SchemaType.STRING }, schemaParams));
    this.enum = enumValues;
  }
  /**
   * @internal
   */
  toJSON() {
    const obj = super.toJSON();
    if (this.enum) {
      obj["enum"] = this.enum;
    }
    return obj;
  }
};
var ArraySchema = class extends Schema {
  constructor(schemaParams, items) {
    super(Object.assign({ type: SchemaType.ARRAY }, schemaParams));
    this.items = items;
  }
  /**
   * @internal
   */
  toJSON() {
    const obj = super.toJSON();
    obj.items = this.items.toJSON();
    return obj;
  }
};
var ObjectSchema = class extends Schema {
  constructor(schemaParams, properties, optionalProperties = []) {
    super(Object.assign({ type: SchemaType.OBJECT }, schemaParams));
    this.properties = properties;
    this.optionalProperties = optionalProperties;
  }
  /**
   * @internal
   */
  toJSON() {
    const obj = super.toJSON();
    obj.properties = Object.assign({}, this.properties);
    const required = [];
    if (this.optionalProperties) {
      for (const propertyKey of this.optionalProperties) {
        if (!this.properties.hasOwnProperty(propertyKey)) {
          throw new AIError("invalid-schema", `Property "${propertyKey}" specified in "optionalProperties" does not exist.`);
        }
      }
    }
    for (const propertyKey in this.properties) {
      if (this.properties.hasOwnProperty(propertyKey)) {
        obj.properties[propertyKey] = this.properties[propertyKey].toJSON();
        if (!this.optionalProperties.includes(propertyKey)) {
          required.push(propertyKey);
        }
      }
    }
    if (required.length > 0) {
      obj.required = required;
    }
    delete obj.optionalProperties;
    return obj;
  }
};
var ImagenImageFormat = class {
  constructor() {
    this.mimeType = "image/png";
  }
  /**
   * Creates an {@link ImagenImageFormat} for a JPEG image.
   *
   * @param compressionQuality - The level of compression (a number between 0 and 100).
   * @returns An {@link ImagenImageFormat} object for a JPEG image.
   *
   * @beta
   */
  static jpeg(compressionQuality) {
    if (compressionQuality && (compressionQuality < 0 || compressionQuality > 100)) {
      logger.warn(`Invalid JPEG compression quality of ${compressionQuality} specified; the supported range is [0, 100].`);
    }
    return { mimeType: "image/jpeg", compressionQuality };
  }
  /**
   * Creates an {@link ImagenImageFormat} for a PNG image.
   *
   * @returns An {@link ImagenImageFormat} object for a PNG image.
   *
   * @beta
   */
  static png() {
    return { mimeType: "image/png" };
  }
};
var VertexAIModel = AIModel;
var VertexAIError = AIError;
function getVertexAI(app = getApp(), options) {
  app = getModularInstance(app);
  const AIProvider = _getProvider(app, AI_TYPE);
  const backend = new VertexAIBackend(options === null || options === void 0 ? void 0 : options.location);
  const identifier = encodeInstanceIdentifier(backend);
  return AIProvider.getImmediate({
    identifier
  });
}
function getAI(app = getApp(), options = { backend: new GoogleAIBackend() }) {
  app = getModularInstance(app);
  const AIProvider = _getProvider(app, AI_TYPE);
  const identifier = encodeInstanceIdentifier(options.backend);
  return AIProvider.getImmediate({
    identifier
  });
}
function getGenerativeModel(ai, modelParams, requestOptions) {
  if (!modelParams.model) {
    throw new AIError("no-model", `Must provide a model name. Example: getGenerativeModel({ model: 'my-model-name' })`);
  }
  return new GenerativeModel(ai, modelParams, requestOptions);
}
function getImagenModel(ai, modelParams, requestOptions) {
  if (!modelParams.model) {
    throw new AIError("no-model", `Must provide a model name. Example: getImagenModel({ model: 'my-model-name' })`);
  }
  return new ImagenModel(ai, modelParams, requestOptions);
}
function registerAI() {
  _registerComponent(new Component(
    AI_TYPE,
    (container, { instanceIdentifier }) => {
      if (!instanceIdentifier) {
        throw new AIError("error", "AIService instance identifier is undefined.");
      }
      const backend = decodeInstanceIdentifier(instanceIdentifier);
      const app = container.getProvider("app").getImmediate();
      const auth = container.getProvider("auth-internal");
      const appCheckProvider = container.getProvider("app-check-internal");
      return new AIService(app, backend, auth, appCheckProvider);
    },
    "PUBLIC"
    /* ComponentType.PUBLIC */
  ).setMultipleInstances(true));
  registerVersion(name, version);
  registerVersion(name, version, "esm2017");
}
registerAI();
export {
  AIError,
  AIModel,
  ArraySchema,
  Backend,
  BackendType,
  BlockReason,
  BooleanSchema,
  ChatSession,
  FinishReason,
  FunctionCallingMode,
  GenerativeModel,
  GoogleAIBackend,
  HarmBlockMethod,
  HarmBlockThreshold,
  HarmCategory,
  HarmProbability,
  HarmSeverity,
  ImagenAspectRatio,
  ImagenImageFormat,
  ImagenModel,
  ImagenPersonFilterLevel,
  ImagenSafetyFilterLevel,
  IntegerSchema,
  Modality,
  NumberSchema,
  ObjectSchema,
  POSSIBLE_ROLES,
  ResponseModality,
  Schema,
  SchemaType,
  StringSchema,
  VertexAIBackend,
  VertexAIError,
  VertexAIModel,
  getAI,
  getGenerativeModel,
  getImagenModel,
  getVertexAI
};
/*! Bundled license information:

@firebase/ai/dist/esm/index.esm2017.js:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *   http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)
  (**
   * @license
   * Copyright 2025 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *   http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)
*/
//# sourceMappingURL=firebase_vertexai.js.map
